import os
import time
import joblib
import streamlit as st
import google.generativeai as genai
from PIL import Image
from PyPDF2 import PdfReader
import docx

# =================== C·∫•u h√¨nh API key ===================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_API_KEY ='AIzaSyBjH-YfcE9aoMqic_62XfkcnzXlS0zCxBQ'# ‚ö†Ô∏è set bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ b·∫£o m·∫≠t key
if not GOOGLE_API_KEY:
    st.error("API Key ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p! Vui l√≤ng set GOOGLE_API_KEY.")
genai.configure(api_key=GOOGLE_API_KEY)

# =================== Th√¥ng tin c√° nh√¢n ===================
OWNER_NAME = "Phan Van Kha - My Thai name is Tauwan"
OWNER_TITLE = "Student - Informatics Teacher Education"
OWNER_UNIVERSITY = "Can Tho University, Viet Nam"
CHATBOT_NAME = "KhaBot"
AI_AVATAR_ICON = "ü§ñ"

# =================== System Prompt ===================
SYSTEM_PROMPT = f"""
You are {CHATBOT_NAME}, an intelligent and helpful AI assistant created by {OWNER_NAME},
who is a {OWNER_TITLE} from {OWNER_UNIVERSITY}.
Always introduce yourself as an AI developed by {OWNER_NAME} when asked who you are.
Be polite, supportive, and educational, speaking naturally in Vietnamese or English depending on the user's language.
"""

# =================== Sidebar & Chat ID ===================
new_chat_id = f'{time.time()}'
os.makedirs('data', exist_ok=True)

try:
    past_chats: dict = joblib.load('data/past_chats_list')
except:
    past_chats = {}

with st.sidebar:
    st.markdown(f"### üßë‚Äçüíª {OWNER_NAME}")
    st.caption(f"{OWNER_TITLE} ‚Äì {OWNER_UNIVERSITY}")
    st.markdown("---")
    st.write("### üí¨ Past Chats")

    if st.session_state.get('chat_id') is None:
        st.session_state.chat_id = st.selectbox(
            label='Select chat',
            options=[new_chat_id] + list(past_chats.keys()),
            format_func=lambda x: past_chats.get(x, 'New Chat')
        )

    if st.button('üÜï New Chat'):
        st.session_state.chat_id = new_chat_id
        st.session_state.messages = []
        st.session_state.gemini_history = []
        st.experimental_rerun()

# =================== H√†m ƒë·ªçc file ===================
def read_file_content(uploaded_file):
    ext = uploaded_file.name.split('.')[-1].lower()
    content = ""
    if ext == "pdf":
        reader = PdfReader(uploaded_file)
        for page in reader.pages:
            content += page.extract_text() + "\n"
    elif ext in ["docx", "doc"]:
        doc = docx.Document(uploaded_file)
        content = "\n".join([p.text for p in doc.paragraphs])
    elif ext in ["txt", "md"]:
        content = uploaded_file.read().decode("utf-8", errors="ignore")
    else:
        content = "(Kh√¥ng th·ªÉ ƒë·ªçc ƒë·ªãnh d·∫°ng file n√†y.)"
    return content.strip()

def chunk_text(text, chunk_size=2000):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

# =================== G·ªçi Gemini ===================
def send_to_gemini(prompt, history, file_content=None, image_file=None):
    model = genai.GenerativeModel("models/gemini-2.5-pro")  # ch·ªçn model c√≥ h·ªó tr·ª£

    parts = [SYSTEM_PROMPT]
    if prompt:
        parts.append(prompt)
    if file_content:
        parts.append(file_content)
    if image_file:
        parts.append(f"[image: {image_file.name}]")  # ho·∫∑c x·ª≠ l√Ω th·ª±c s·ª± h√¨nh ·∫£nh theo API

    response = model.generate_content(
        [{"role": "user", "parts": parts}],
        generation_config={"temperature": 0.7}
    )

    reply_text = response.text or "(Kh√¥ng c√≥ ph·∫£n h·ªìi)"
    history.append({"role": "user", "parts": parts})
    history.append({"role": "model", "parts": [reply_text]})
    return reply_text


# =================== Kh·ªüi t·∫°o session_state ===================
if "messages" not in st.session_state:
    st.session_state.messages = []

if "gemini_history" not in st.session_state:
    st.session_state.gemini_history = []

# =================== Header ===================
st.title(f"ü§ñ {CHATBOT_NAME}")
st.caption(f"AI Assistant by {OWNER_NAME} ‚Äì {OWNER_UNIVERSITY}")

# =================== Hi·ªÉn th·ªã tin nh·∫Øn c≈© ===================
for msg in st.session_state.messages:
    with st.chat_message(name=msg["role"], avatar=AI_AVATAR_ICON if msg["role"] == "ai" else "üßë"):
        st.markdown(msg["content"])

# =================== Upload file & ·∫£nh ===================
uploaded_file = st.file_uploader("üìÑ T·∫£i file (PDF, DOCX, TXT, MD)", type=["pdf", "docx", "txt", "md"])
uploaded_image = st.file_uploader("üì∑ T·∫£i ·∫£nh (tu·ª≥ ch·ªçn)", type=["png", "jpg", "jpeg"])

file_text = ""
if uploaded_file:
    file_text = read_file_content(uploaded_file)
    st.success(f"ƒê√£ t·∫£i file: {uploaded_file.name}")
    with st.expander("üìö Xem n·ªôi dung file"):
        st.text(file_text[:2000] + ("..." if len(file_text) > 2000 else ""))

# =================== X·ª≠ l√Ω chat ===================
if prompt := st.chat_input("üí¨ Nh·∫≠p c√¢u h·ªèi ho·∫∑c m√¥ t·∫£ c·ªßa b·∫°n..."):
    st.session_state.messages.append(dict(role='user', content=prompt))

    chunks = chunk_text(file_text, chunk_size=2000) if file_text else [""]

    full_reply = ""
    for chunk in chunks:
        reply = send_to_gemini(prompt, st.session_state.gemini_history, file_content=chunk, image_file=uploaded_image)
        full_reply += reply + "\n"

    with st.chat_message(name="ai", avatar=AI_AVATAR_ICON):
        st.markdown(full_reply.strip())

    st.session_state.messages.append(dict(role="ai", content=full_reply.strip()))

    # L∆∞u l·∫°i l·ªãch s·ª≠
    past_chats[st.session_state.chat_id] = (
        st.session_state.messages[0]['content'] if st.session_state.messages else 'Untitled'
    )
    joblib.dump(past_chats, 'data/past_chats_list')
